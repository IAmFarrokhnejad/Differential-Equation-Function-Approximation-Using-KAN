{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeTSHn0NOoea"
      },
      "outputs": [],
      "source": [
        "!pip install numpy matplotlib torch pandas pykan jax scikit-learn polars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2mUPm6fPYrz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from kan import MultKAN\n",
        "import os\n",
        "\n",
        "lib = ['x','x^2','x^3','x^4','exp','log','sqrt','tanh','sin','abs']\n",
        "EPOCHS = 150\n",
        "LEARNING_RATE = 0.008\n",
        "GRIDS = 100\n",
        "SPLINE = 3\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Helper function to print comparison table\n",
        "def print_comparison_table(t_eval_np, y_pred, y_exact_eval, example_number, output_dir, meanSe, meanAe):\n",
        "    table_lines = []\n",
        "    table_lines.append(f\"\\nComparison Table for Example {example_number}:\")\n",
        "    table_lines.append(f\"{'t':<10}{'Network Output':<20}{'Exact Solution':<20}{'MAE':<10}{'MSE':<10}\")\n",
        "    table_lines.append(\"-\" * 90)\n",
        "    for t, pred, exact, mae, mse in zip(t_eval_np.flatten(), y_pred.flatten(), y_exact_eval.flatten(), np.abs(y_pred.flatten() - y_exact_eval.flatten()), (y_pred.flatten() - y_exact_eval.flatten())**2):\n",
        "        table_lines.append(f\"{t:<10.4f}{pred:<20.6f}{exact:<20.6f}{mae}{mse}\")\n",
        "    table_lines.append(f\"MSE:{meanSe}\")\n",
        "    table_lines.append(f\"MAE:{meanAe}\")\n",
        "\n",
        "\n",
        "    # Write table to file\n",
        "    file_path = os.path.join(output_dir, f\"comparison_table_example_{example_number}.txt\")\n",
        "    with open(file_path, \"a\") as f:\n",
        "        f.write(\"\\n\".join(table_lines))\n",
        "    print(f\"Comparison table for Example {example_number} saved to {file_path}\")\n",
        "\n",
        "def save_plot(t_eval_np, y_pred, y_exact_eval, example_number, output_dir):\n",
        "    plt.figure()\n",
        "    plt.plot(t_eval_np, y_exact_eval, label='Exact Solution', color='g', marker='s', markersize=6, markerfacecolor='none', linestyle='--', linewidth=1)\n",
        "    plt.plot(t_eval_np, y_pred, label='KAN Solution', color='b', marker='o', markersize=4, linestyle='-', linewidth=1)\n",
        "    plt.legend()\n",
        "\n",
        "    # Modify font style to italicize the title, labels, and legend\n",
        "    plt.title(' ', fontstyle='italic')\n",
        "    plt.xlabel('t', fontstyle='italic')\n",
        "    plt.ylabel('y(t)', fontstyle='italic')\n",
        "\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Save the figure\n",
        "    file_path = os.path.join(output_dir, f\"example_{example_number}_solution.png\")\n",
        "    plt.savefig(file_path, dpi=1800)\n",
        "    plt.close()\n",
        "    print(f\"Plot for Example {example_number} saved to {file_path}\")\n",
        "\n",
        "\n",
        "\n",
        "def train_model_with_physics(model, epochs, optimizer, t_train, ode_loss, patience=100):\n",
        "    # Initialize values\n",
        "    best_loss = float('inf')\n",
        "    counter = 0\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Get model prediction (z(t))\n",
        "            z_pred = model(t_train)\n",
        "\n",
        "            # Calculate loss using ode_loss(t, z) function\n",
        "            total_loss = ode_loss(t_train, z_pred)\n",
        "            total_loss.backward()\n",
        "            return total_loss\n",
        "\n",
        "        loss = optimizer.step(closure)\n",
        "\n",
        "        if loss.item() < best_loss:\n",
        "            best_loss = loss.item()\n",
        "            counter = 0\n",
        "        else:\n",
        "            counter += 1\n",
        "        if counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "        # Log and store loss\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item()}\")\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    # # Plot loss curve\n",
        "    # plt.plot(losses)\n",
        "    # plt.xlabel('Epochs')\n",
        "    # plt.ylabel('Loss')\n",
        "    # plt.title('Training Loss Curve')\n",
        "    # plt.grid(True)\n",
        "    # plt.show()\n",
        "    model.plot(scale=1)\n",
        "    plt.plot()\n",
        "    plt.show()\n",
        "    return model\n",
        "\n",
        "def solve_example1(architecture, output_dir):\n",
        "    # Initial condition values (y(a) = A | y(0) = 1)\n",
        "    A = 1\n",
        "    a = 0\n",
        "\n",
        "    # Define model\n",
        "    model = MultKAN(\n",
        "        width=architecture,\n",
        "        grid=GRIDS,\n",
        "        k=SPLINE,\n",
        "        device=device,\n",
        "        mult_arity = 2,\n",
        "        noise_scale = 0.1,\n",
        "        scale_base_mu = 0,\n",
        "        scale_base_sigma = 1,\n",
        "        base_fun = torch.nn.SiLU(),\n",
        "        symbolic_enabled = False, # for efficiency\n",
        "        affine_trainable = True, # update (sub)node_scale, (sub)node_bias\n",
        "        grid_eps = 1, # 1 - uniform grid, 0 - percentiles\n",
        "        grid_range = [-5, 5],\n",
        "        seed = 1107,\n",
        "        sparse_init = False,\n",
        "        first_init = True,\n",
        "        )\n",
        "\n",
        "    # Function for calculating loss\n",
        "    # dy(t)/dt = f(t,y); => yt(t) = A + (t-a)z(t); z(t) - model output\n",
        "    # Error = ((dyt(t)/dt - f(t,y))**2)/2\n",
        "    def ode_loss(t, z):\n",
        "        # Compute trial solution y\n",
        "        y = A + (t - a) * z\n",
        "\n",
        "        # Calculate dz(t)/dt using autograd\n",
        "        dz_dt = torch.autograd.grad(z, t, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
        "\n",
        "        # Substitute into dy/dt = z(t) + (t - a) * dz(t)/dt\n",
        "        dy_dt = z + (t - a) * dz_dt\n",
        "\n",
        "        # Formulate the residual with dy/dt_actual\n",
        "        f_term = (t + ((1 + 3 * t**2) / (1 + t + t**3))) * y\n",
        "        g_term = 2 * t + t**3 + t**2 * ((1 + 3 * t**2) / (1 + t + t**3))\n",
        "        return torch.mean(((dy_dt - (g_term - f_term))**2))/2\n",
        "\n",
        "    # Training data\n",
        "    t_train = torch.linspace(0, 1, 100, device=device).reshape(-1, 1).requires_grad_()\n",
        "    # # Modify data for 2-input KAN (worse performance, do not pursue)\n",
        "    # t_train = torch.cat([t_train, t_train], dim=1)\n",
        "    # print(t_train)\n",
        "\n",
        "    # Define optimizer\n",
        "    optimizer = torch.optim.LBFGS(model.parameters(), lr=LEARNING_RATE, max_iter=20, tolerance_grad=1e-7, tolerance_change=1e-9, history_size=50)\n",
        "\n",
        "    # Train model\n",
        "    model = train_model_with_physics(model, epochs=EPOCHS, optimizer=optimizer, t_train=t_train, ode_loss=ode_loss)\n",
        "\n",
        "    # Evaluate and plot\n",
        "    t_eval = torch.linspace(0, 1, 21, device=device).reshape(-1, 1).requires_grad_()\n",
        "    y_pred = A + (t_eval - a) * model(t_eval).detach()\n",
        "    y_pred = y_pred.detach().to('cpu').numpy()\n",
        "    t_eval_np = t_eval.detach().to('cpu').numpy()\n",
        "    y_exact_eval = (np.exp(-t_eval_np**2 / 2) + t_eval_np**5 + t_eval_np**3 + t_eval_np**2) / (t_eval_np**3 + t_eval_np + 1)\n",
        "\n",
        "    # Display Results and Comparison\n",
        "    MSE = (torch.sum((torch.tensor(y_exact_eval) - y_pred)**2))/200\n",
        "    MAE = (torch.sum((torch.abs(torch.tensor(y_exact_eval) - y_pred))))/200\n",
        "    print(f\"MSE for example 1: {MSE}\")\n",
        "    print(f\"MAE for example 1: {MAE}\")\n",
        "    print_comparison_table(t_eval_np, y_pred, y_exact_eval, 1, output_dir, MSE, MAE)\n",
        "\n",
        "\n",
        "    # # Extract the symbolic formula for z(t)\n",
        "    # print(f\"Symbolic Expression for KAN: {symbolic_expr}\")\n",
        "    # symbolic_expr = model.symbolic_formula()\n",
        "\n",
        "\n",
        "    return t_eval_np, y_pred, y_exact_eval\n",
        "\n",
        "def solve_example2(architecture, output_dir):\n",
        "    # Initial condition values (y(a) = A | y(0) = 3)\n",
        "    A = 3\n",
        "    a = 0\n",
        "\n",
        "    # Define model\n",
        "    model = MultKAN(\n",
        "        width=architecture,\n",
        "        grid=GRIDS,\n",
        "        k=SPLINE,\n",
        "        device=device,\n",
        "        mult_arity = 2,\n",
        "        noise_scale = 0.1,\n",
        "        scale_base_mu = 0,\n",
        "        scale_base_sigma = 1,\n",
        "        base_fun = torch.nn.SiLU(),\n",
        "        symbolic_enabled = False, # for efficiency\n",
        "        affine_trainable = True, # update (sub)node_scale, (sub)node_bias\n",
        "        grid_eps = 1, # 1 - uniform grid, 0 - percentiles\n",
        "        grid_range = [-5, 5],\n",
        "        seed = 1107,\n",
        "        sparse_init = False,\n",
        "        first_init = True,\n",
        "        )\n",
        "\n",
        "    # Function for calculating loss\n",
        "    # dy(t)/dt = f(t,y); => yt(t) = A + (t-a)z(t); z(t) - model output\n",
        "    # Error = ((dyt(t)/dt - f(t,y))**2)/2\n",
        "    def ode_loss(t, z):\n",
        "        # Compute trial solution y\n",
        "        y = A + (t - a) * z\n",
        "\n",
        "        # Calculate dz(t)/dt using autograd\n",
        "        dz_dt = torch.autograd.grad(z, t, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
        "\n",
        "        # Substitute into dy/dt = z(t) + (t - a) * dz(t)/dt\n",
        "        dy_dt = z + (t - a) * dz_dt\n",
        "\n",
        "        # Formulate the residual with dy/dt_actual\n",
        "        f_term = 2 * y\n",
        "        g_term = torch.cos(4 * t)\n",
        "        return torch.mean(((dy_dt - (g_term - f_term))**2))/2\n",
        "\n",
        "    # Training data\n",
        "    t_train = torch.linspace(0, 3, 150, device=device).reshape(-1, 1).requires_grad_()\n",
        "\n",
        "    # Define optimizer\n",
        "    optimizer = torch.optim.LBFGS(model.parameters(), lr=LEARNING_RATE, max_iter=20, tolerance_grad=1e-7, tolerance_change=1e-9, history_size=50)\n",
        "\n",
        "    # Train model\n",
        "    model = train_model_with_physics(model, epochs=EPOCHS, optimizer=optimizer, t_train=t_train, ode_loss=ode_loss)\n",
        "\n",
        "    # Evaluate and plot\n",
        "    t_eval = torch.linspace(0, 3, 21, device=device).reshape(-1, 1).requires_grad_()\n",
        "    y_pred = A + (t_eval - a) * model(t_eval).detach()\n",
        "    y_pred = y_pred.detach().to('cpu').numpy()\n",
        "    t_eval_np = t_eval.detach().to('cpu').numpy()\n",
        "    y_exact_eval = (np.sin(4 * t_eval_np) / 5 + np.cos(4 * t_eval_np) / 10 + 2.9 * np.exp(-2 * t_eval_np))\n",
        "\n",
        "    # Display Results and Comparison\n",
        "    MSE = (torch.sum((torch.tensor(y_exact_eval) - y_pred)**2))/200\n",
        "    MAE = (torch.sum((torch.abs(torch.tensor(y_exact_eval) - y_pred))))/200\n",
        "    print(f\"MSE for example 2: {MSE}\")\n",
        "    print(f\"MAE for example 2: {MAE}\")\n",
        "    print_comparison_table(t_eval_np, y_pred, y_exact_eval, 2, output_dir, MSE, MAE)\n",
        "\n",
        "\n",
        "    # # Extract the symbolic formula for z(t)\n",
        "    # print(f\"Symbolic Expression for KAN: {symbolic_expr}\")\n",
        "    # symbolic_expr = model.symbolic_formula()\n",
        "\n",
        "    return t_eval_np, y_pred, y_exact_eval\n",
        "\n",
        "def solve_example3(architecture, output_dir):\n",
        "    # Initial condition values (y(a) = A | y(0) = 0.5)\n",
        "    A = 0.5\n",
        "    a = 0\n",
        "\n",
        "    # Define model\n",
        "    model = MultKAN(\n",
        "        width=architecture,\n",
        "        grid=GRIDS,\n",
        "        k=SPLINE,\n",
        "        device=device,\n",
        "        mult_arity = 2,\n",
        "        noise_scale = 0.1,\n",
        "        scale_base_mu = 0,\n",
        "        scale_base_sigma = 1,\n",
        "        base_fun = torch.nn.SiLU(),\n",
        "        symbolic_enabled = False, # for efficiency\n",
        "        affine_trainable = True, # update (sub)node_scale, (sub)node_bias\n",
        "        grid_eps = 1, # 1 - uniform grid, 0 - percentiles\n",
        "        grid_range = [-5, 5],\n",
        "        seed = 1107,\n",
        "        sparse_init = False,\n",
        "        first_init = True,\n",
        "        )\n",
        "\n",
        "    # Function for calculating loss\n",
        "    # dy(t)/dt = f(t,y); => yt(t) = A + (t-a)z(t); z(t) - model output\n",
        "    # Error = ((dyt(t)/dt - f(t,y))**2)/2\n",
        "    def ode_loss(t, z):\n",
        "        # Compute trial solution y\n",
        "        y = A + (t - a) * z\n",
        "\n",
        "        # Calculate dz(t)/dt using autograd\n",
        "        dz_dt = torch.autograd.grad(z, t, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
        "\n",
        "        # Substitute into dy/dt = z(t) + (t - a) * dz(t)/dt\n",
        "        dy_dt = z + (t - a) * dz_dt\n",
        "\n",
        "        # Formulate the residual with dy/dt_actual\n",
        "        g_term = y - t**2 + 1\n",
        "        return torch.mean(((dy_dt - g_term)**2))/2\n",
        "\n",
        "    # Training data\n",
        "    t_train = torch.linspace(0, 2, 100, device=device).reshape(-1, 1).requires_grad_()\n",
        "\n",
        "    # Define optimizer\n",
        "    optimizer = torch.optim.LBFGS(model.parameters(), lr=LEARNING_RATE, max_iter=20, tolerance_grad=1e-7, tolerance_change=1e-9, history_size=50)\n",
        "\n",
        "    # Train model\n",
        "    model = train_model_with_physics(model, epochs=EPOCHS, optimizer=optimizer, t_train=t_train, ode_loss=ode_loss)\n",
        "\n",
        "    # Evaluate and plot\n",
        "    t_eval = torch.linspace(0, 2, 21, device=device).reshape(-1, 1).requires_grad_()\n",
        "    y_pred = A + (t_eval - a) * model(t_eval).detach()\n",
        "    y_pred = y_pred.detach().to('cpu').numpy()\n",
        "    t_eval_np = t_eval.detach().to('cpu').numpy()\n",
        "    y_exact_eval = (t_eval_np + 1)**2 - 0.5 * np.exp(t_eval_np)\n",
        "\n",
        "    # Display Results and Comparison\n",
        "    MSE = (torch.sum((torch.tensor(y_exact_eval) - y_pred)**2))/200\n",
        "    MAE = (torch.sum((torch.abs(torch.tensor(y_exact_eval) - y_pred))))/200\n",
        "    print(f\"MSE for example 3: {MSE}\")\n",
        "    print(f\"MAE for example 3: {MAE}\")\n",
        "    print_comparison_table(t_eval_np, y_pred, y_exact_eval, 3, output_dir, MSE, MAE)\n",
        "\n",
        "    # # Extract the symbolic formula for z(t)\n",
        "    # print(f\"Symbolic Expression for KAN: {symbolic_expr}\")\n",
        "    # symbolic_expr = model.symbolic_formula()\n",
        "\n",
        "    return t_eval_np, y_pred, y_exact_eval\n",
        "\n",
        "def plot_results(t1, y1, y1_exact, t2, y2, y2_exact, t3, y3, y3_exact, architecture):\n",
        "    print(\"Results for architecture: \", architecture)\n",
        "    plt.figure(figsize=(18, 5))\n",
        "\n",
        "    # Plot Example 1\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(t1, y1, 'b-', label='KAN Solution')\n",
        "    plt.scatter(t1, y1, color='blue', s=15, label='KAN Points')  # Add points\n",
        "    plt.plot(t1, y1_exact, 'g--', label='Exact Solution')\n",
        "    plt.scatter(t1, y1_exact, color='green', s=15, label='Exact Points')  # Add points\n",
        "    plt.title('Example 1: Solution')\n",
        "    plt.xlabel('t')\n",
        "    plt.ylabel('y(t)')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Example 2\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(t2, y2, 'r-', label='KAN Solution')\n",
        "    plt.scatter(t2, y2, color='red', s=15, label='KAN Points')  # Add points\n",
        "    plt.plot(t2, y2_exact, 'g--', label='Exact Solution')\n",
        "    plt.scatter(t2, y2_exact, color='green', s=15, label='Exact Points')  # Add points\n",
        "    plt.title('Example 2: Solution')\n",
        "    plt.xlabel('t')\n",
        "    plt.ylabel('y(t)')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Example 3\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(t3, y3, 'm-', label='KAN Solution')\n",
        "    plt.scatter(t3, y3, color='magenta', s=15, label='KAN Points')  # Add points\n",
        "    plt.plot(t3, y3_exact, 'c--', label='Exact Solution')\n",
        "    plt.scatter(t3, y3_exact, color='cyan', s=15, label='Exact Points')  # Add points\n",
        "    plt.title('Example 3: Solution')\n",
        "    plt.xlabel('t')\n",
        "    plt.ylabel('y(t)')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the figure\n",
        "    architecture_str = \"_\".join(map(str, architecture)).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"-\").replace(\" \", \"\")\n",
        "    filename = f\"results_architecture_{architecture_str}.png\"\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    print(f\"Figure saved as {filename}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    output_dir = \"results\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # architectures = [\n",
        "    #     [1, 50, 20, 1],\n",
        "    #     [1, 64, 32, 1],\n",
        "    #     [1, [50, 20], 10, 1],\n",
        "    #     [1, [50, 20], [20, 8], 1],\n",
        "    #     ]\n",
        "    architecture = [1, 14, 8, 1]\n",
        "\n",
        "    for i in range(200):\n",
        "\n",
        "        print(\"Solving Example 1...\")\n",
        "        t1, y1, y1_exact = solve_example1(architecture, output_dir)\n",
        "        save_plot(t1, y1, y1_exact, 1, output_dir)\n",
        "\n",
        "        print(\"Solving Example 2...\")\n",
        "        t2, y2, y2_exact = solve_example2(architecture, output_dir)\n",
        "        save_plot(t2, y2, y2_exact, 2, output_dir)\n",
        "\n",
        "        print(\"Solving Example 3...\")\n",
        "        t3, y3, y3_exact = solve_example3(architecture, output_dir)\n",
        "        save_plot(t3, y3, y3_exact, 3, output_dir)\n",
        "\n",
        "        # print(\"Plotting results...\")\n",
        "        # plot_results(t1, y1, y1_exact, t2, y2, y2_exact, t3, y3, y3_exact, architecture)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}